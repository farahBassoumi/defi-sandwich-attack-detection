{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farahBassoumi/defi-sandwich-attack-detection/blob/main/sybil_detection_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e31d9d6c-5644-4bf9-901f-adf0271a3f92",
      "metadata": {
        "id": "e31d9d6c-5644-4bf9-901f-adf0271a3f92"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams['font.family'] = 'Arial'  # Avoid glyph warnings\n",
        "\n",
        "\n",
        "class InteractiveSybilDetectionPipeline:\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "        self.processed_df = None\n",
        "        self.feature_importance = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.encoders = {}\n",
        "        self.step_history = []\n",
        "        self.model = None\n",
        "        self.selected_features = None\n",
        "        self.predictions_df = None\n",
        "        self.training_feature_order = None\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"SYBIL DETECTION PIPELINE INITIALIZED\")\n",
        "        print(\"=\" * 60)\n",
        "        self._show_dataset_overview(self.df, \"Original Dataset\")\n",
        "\n",
        "    def _show_dataset_overview(self, df, title):\n",
        "        print(f\"\\n{title.upper()}:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
        "\n",
        "        if 'is_sybil' in df.columns:\n",
        "            dist = df['is_sybil'].value_counts()\n",
        "            total = len(df)\n",
        "            print(\"Target Distribution:\")\n",
        "            non_sybil_count = dist.get(False, 0)\n",
        "            sybil_count = dist.get(True, 0)\n",
        "            print(f\"  • Non-Sybil: {non_sybil_count:,} ({non_sybil_count / total * 100:.1f}%)\")\n",
        "            print(f\"  • Sybil:     {sybil_count:,} ({sybil_count / total * 100:.1f}%)\")\n",
        "        else:\n",
        "            print(\"Target Distribution: 'is_sybil' column not found.\")\n",
        "\n",
        "        missing_count = df.isnull().sum().sum()\n",
        "        if missing_count > 0:\n",
        "            print(f\"Missing Values: {missing_count:,}\")\n",
        "        else:\n",
        "            print(\"Missing Values: None\")\n",
        "\n",
        "\n",
        "    def aggregate_features(self, inference_mode=False):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"PHASE 1: FEATURE AGGREGATION\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Preprocessing steps\n",
        "        preprocessing_tasks = [\n",
        "            (\"Converting detecttime to datetime format\",\n",
        "             lambda: pd.to_datetime(self.df['detecttime'], errors='coerce') if 'detecttime' in self.df.columns else None),\n",
        "            (\"Creating detect_date column\",\n",
        "             lambda: setattr(self.df, 'detect_date', self.df['detecttime'].dt.date) if 'detect_date' not in self.df.columns and 'detecttime' in self.df.columns else None),\n",
        "            (\"Converting value column to numeric\",\n",
        "             lambda: pd.to_numeric(self.df['value'], errors='coerce') if 'value' in self.df.columns else None)\n",
        "        ]\n",
        "\n",
        "        print(\"\\nPreprocessing Data...\")\n",
        "        with tqdm(total=len(preprocessing_tasks), desc=\"Preprocessing\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\",\n",
        "                  colour='blue') as pbar:\n",
        "            for desc, func in preprocessing_tasks:\n",
        "                pbar.set_description(f\"Preprocessing: {desc}\")\n",
        "                result = func()\n",
        "                if result is not None:\n",
        "                    if 'detecttime' in desc.lower():\n",
        "                        self.df['detecttime'] = result\n",
        "                    elif 'value' in desc.lower():\n",
        "                        self.df['value'] = result\n",
        "                pbar.update(1)\n",
        "                time.sleep(0.1)\n",
        "\n",
        "        # Numeric feature aggregation\n",
        "        numeric_cols = [\n",
        "            'nonce', 'gas', 'gasprice', 'value', 'blockspending',\n",
        "            'time_pending_by_blocknative', 'gasused', 'maxpriorityfeepergas',\n",
        "            'maxfeepergas', 'basefeepergas', 'time_pending',\n",
        "            'was_evicted', 'was_rejected'\n",
        "        ]\n",
        "\n",
        "        available_numeric_cols = [col for col in numeric_cols if col in self.df.columns and pd.api.types.is_numeric_dtype(self.df[col])]\n",
        "        aggregated = []\n",
        "\n",
        "        print(f\"\\nAggregating {len(available_numeric_cols)} numeric features...\")\n",
        "        with tqdm(total=len(available_numeric_cols), desc=\"Numeric Aggregation\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\",\n",
        "                  colour='green') as pbar:\n",
        "            for col in available_numeric_cols:\n",
        "                pbar.set_description(f\"Aggregating: {col}\")\n",
        "                agg = self.df.groupby('fromaddress')[col].agg(['count', 'mean', 'std', 'min', 'max', 'median'])\n",
        "                aggregated.append(agg.add_prefix(f\"{col}_\"))\n",
        "                pbar.update(1)\n",
        "                time.sleep(0.05)\n",
        "\n",
        "        # Categorical and temporal aggregation\n",
        "        group_dict = {\n",
        "            'hash': 'count',\n",
        "            'status': lambda x: (x == 'confirmed').sum(),\n",
        "            'failurereason': lambda x: (x != 'none').sum(),\n",
        "            'toaddress': 'nunique',\n",
        "            'type': lambda x: x.mode().iloc[0] if not x.mode().empty else 'unknown',\n",
        "            'region': lambda x: x.mode().iloc[0] if not x.mode().empty else 'unknown',\n",
        "            'drop_reason': lambda x: x.notna().sum(),\n",
        "            'detecttime': lambda x: (x.max() - x.min()).total_seconds() if x.notna().any() else 0,\n",
        "            'detect_date': 'nunique',\n",
        "        }\n",
        "        if not inference_mode and 'is_sybil' in self.df.columns:\n",
        "            group_dict['is_sybil'] = 'any'\n",
        "\n",
        "        print(\"\\nAggregating transaction statistics...\")\n",
        "        tx_stats = self.df.groupby('fromaddress').agg(group_dict).rename(columns={\n",
        "            'hash': 'total_transactions',\n",
        "            'status': 'successful_transactions',\n",
        "            'failurereason': 'failed_transactions',\n",
        "            'toaddress': 'unique_recipients',\n",
        "            'type': 'primary_tx_type',\n",
        "            'region': 'primary_region',\n",
        "            'drop_reason': 'dropped_transactions',\n",
        "            'detecttime': 'activity_timespan_seconds',\n",
        "            'detect_date': 'active_days',\n",
        "            'is_sybil': 'is_sybil' if not inference_mode else None\n",
        "        })\n",
        "\n",
        "        aggregated.append(tx_stats)\n",
        "        self.processed_df = pd.concat(aggregated, axis=1)\n",
        "\n",
        "        # Create derived features\n",
        "        print(\"Creating derived ratio features...\")\n",
        "        total_tx = self.processed_df['total_transactions'].replace(0, np.nan)\n",
        "        self.processed_df['success_rate'] = self.processed_df['successful_transactions'] / total_tx\n",
        "        self.processed_df['failure_rate'] = self.processed_df['failed_transactions'] / total_tx\n",
        "        self.processed_df['unique_recipient_ratio'] = self.processed_df['unique_recipients'] / total_tx\n",
        "        self.processed_df['drop_rate'] = self.processed_df['dropped_transactions'] / total_tx\n",
        "        self.processed_df['tx_frequency'] = self.processed_df['total_transactions'] / np.maximum(self.processed_df['active_days'], 1)\n",
        "\n",
        "        # Fill any NaNs created by division\n",
        "        self.processed_df.fillna(0, inplace=True)\n",
        "\n",
        "        print(f\"\\nFeature aggregation completed successfully.\")\n",
        "        print(f\"Result: {len(self.processed_df):,} addresses with {self.processed_df.shape[1]} features\")\n",
        "\n",
        "    def handle_missing_values(self, threshold_pct=0):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"PHASE 2: MISSING VALUE HANDLING\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        missing_pct = (self.processed_df.isnull().mean()) * 100\n",
        "        cols_to_fill = missing_pct[missing_pct > threshold_pct].index.tolist()\n",
        "\n",
        "        if not cols_to_fill:\n",
        "            print(\"No missing values found - skipping this phase.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Processing {len(cols_to_fill)} columns with missing values...\")\n",
        "\n",
        "        with tqdm(total=len(cols_to_fill), desc=\"Filling Missing Values\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\",\n",
        "                  colour='yellow') as pbar:\n",
        "            for col in cols_to_fill:\n",
        "                pbar.set_description(f\"Filling: {col[:30]}\")\n",
        "                if self.processed_df[col].dtype == 'object':\n",
        "                    mode = self.processed_df[col].mode()\n",
        "                    fill_val = mode.iloc[0] if not mode.empty else 'unknown'\n",
        "                else:\n",
        "                    fill_val = self.processed_df[col].median()\n",
        "                self.processed_df[col] = self.processed_df[col].fillna(fill_val)\n",
        "                pbar.update(1)\n",
        "\n",
        "        remaining_nulls = self.processed_df.isnull().sum().sum()\n",
        "        print(f\"Missing value handling completed. Remaining nulls: {remaining_nulls}\")\n",
        "\n",
        "    def encode_categorical_features(self, inference_mode=False):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"PHASE 3: CATEGORICAL ENCODING\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        categorical_columns = self.processed_df.select_dtypes(include=['object']).columns.tolist()\n",
        "        categorical_columns = [col for col in categorical_columns if col != 'is_sybil']\n",
        "\n",
        "        if not categorical_columns:\n",
        "            print(\"No categorical features found - skipping this phase.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Encoding {len(categorical_columns)} categorical features...\")\n",
        "\n",
        "        with tqdm(total=len(categorical_columns), desc=\"Encoding Categories\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\",\n",
        "                  colour='cyan') as pbar:\n",
        "            for col in categorical_columns:\n",
        "                pbar.set_description(f\"Encoding: {col}\")\n",
        "                if inference_mode:\n",
        "                    if col in self.encoders:\n",
        "                        le = self.encoders[col]\n",
        "                        self.processed_df[col] = self.processed_df[col].map(\n",
        "                            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
        "                        )\n",
        "                    else:\n",
        "                        self.processed_df[col] = -1\n",
        "                else:\n",
        "                    le = LabelEncoder()\n",
        "                    self.processed_df[col] = le.fit_transform(self.processed_df[col].astype(str))\n",
        "                    self.encoders[col] = le\n",
        "                pbar.update(1)\n",
        "\n",
        "        print(f\"Categorical encoding completed for {len(categorical_columns)} features.\")\n",
        "\n",
        "    def remove_low_variance_features(self, threshold=0.01, inference_mode=False):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"PHASE 4: LOW VARIANCE FEATURE REMOVAL\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        numeric_df = self.processed_df.select_dtypes(include=[np.number])\n",
        "        if not inference_mode and 'is_sybil' in numeric_df.columns:\n",
        "            numeric_df = numeric_df.drop(columns='is_sybil')\n",
        "\n",
        "        print(\"Analyzing feature variance...\")\n",
        "        low_var_cols = numeric_df.var()[numeric_df.var() < threshold].index.tolist()\n",
        "\n",
        "        if low_var_cols:\n",
        "            self.processed_df.drop(columns=low_var_cols, inplace=True)\n",
        "            print(f\"Removed {len(low_var_cols)} low variance features:\")\n",
        "            for col in low_var_cols[:5]:  # Show first 5\n",
        "                print(f\"  • {col}\")\n",
        "            if len(low_var_cols) > 5:\n",
        "                print(f\"  • ... and {len(low_var_cols) - 5} more\")\n",
        "        else:\n",
        "            print(\"No low variance features found.\")\n",
        "\n",
        "    def prepare_for_modeling(self, test_size=0.2, random_state=42):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"PHASE 5: DATA PREPARATION FOR MODELING\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        X = self.processed_df.drop(columns='is_sybil')\n",
        "        y = self.processed_df['is_sybil']\n",
        "        self.training_feature_order = X.columns.tolist()\n",
        "\n",
        "        print(\"Scaling features...\")\n",
        "        X_scaled = pd.DataFrame(self.scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "        print(\"Splitting dataset...\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_scaled, y, test_size=test_size, stratify=y, random_state=random_state\n",
        "        )\n",
        "\n",
        "        print(f\"Dataset prepared successfully:\")\n",
        "        print(f\"  • Training set: {len(X_train):,} samples\")\n",
        "        print(f\"  • Test set: {len(X_test):,} samples\")\n",
        "        print(f\"  • Features: {len(X_scaled.columns)}\")\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def run_model_with_top_17_features(self, X_train, X_test, y_train, y_test):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"PHASE 6: MODEL TRAINING & EVALUATION\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        print(\"Selecting top 17 features using mutual information...\")\n",
        "        selector = SelectKBest(score_func=mutual_info_classif, k=17)\n",
        "        X_train_sel = selector.fit_transform(X_train, y_train)\n",
        "        X_test_sel = selector.transform(X_test)\n",
        "        self.selected_features = X_train.columns[selector.get_support()].tolist()\n",
        "\n",
        "        print(\"\\nSelected Features:\")\n",
        "        for i, feature in enumerate(self.selected_features, 1):\n",
        "            print(f\"  {i:2d}. {feature}\")\n",
        "\n",
        "        print(\"\\nApplying SMOTE for class balancing...\")\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_train_res, y_train_res = smote.fit_resample(X_train_sel, y_train)\n",
        "\n",
        "        print(f\"Training set after SMOTE: {len(X_train_res):,} samples\")\n",
        "\n",
        "        print(\"\\nTraining XGBoost classifier...\")\n",
        "        self.model = XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            eval_metric='logloss',\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbosity=0  # Suppress XGBoost output\n",
        "        )\n",
        "\n",
        "        with tqdm(total=1, desc=\"Training Model\",\n",
        "                  bar_format=\"{l_bar}{bar}| {elapsed}\",\n",
        "                  colour='magenta') as pbar:\n",
        "            self.model.fit(X_train_res, y_train_res)\n",
        "            pbar.update(1)\n",
        "\n",
        "        print(\"\\nGenerating predictions...\")\n",
        "        y_probs = self.model.predict_proba(X_test_sel)[:, 1]\n",
        "        y_pred = (y_probs >= 0.7).astype(int)\n",
        "\n",
        "        self.predictions_df = pd.DataFrame({\n",
        "            'y_true': y_test.values,\n",
        "            'y_pred': y_pred,\n",
        "            'y_prob': y_probs\n",
        "        }).reset_index(drop=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"MODEL EVALUATION RESULTS (Threshold = 0.7)\")\n",
        "        print(\"=\" * 60)\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print(f\"ROC AUC Score: {roc_auc_score(y_test, y_probs):.4f}\")\n",
        "\n",
        "    def predict_sybil_addresses(self, new_df):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"INFERENCE PIPELINE\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        self.df = new_df.copy()\n",
        "\n",
        "        inference_steps = [\n",
        "            (\"Feature Aggregation\", self.aggregate_features, True),\n",
        "            (\"Missing Value Handling\", self.handle_missing_values, None),\n",
        "            (\"Categorical Encoding\", self.encode_categorical_features, True),\n",
        "            (\"Low Variance Removal\", self.remove_low_variance_features, True),\n",
        "            (\"Feature Alignment & Prediction\", self._align_and_predict, None)\n",
        "        ]\n",
        "\n",
        "        with tqdm(total=len(inference_steps), desc=\"Inference Progress\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\",\n",
        "                  colour='red') as pbar:\n",
        "            for step_name, func, *args in inference_steps:\n",
        "                pbar.set_description(f\"Running: {step_name}\")\n",
        "                if args and args[0] is not None:\n",
        "                    func(args[0])\n",
        "                else:\n",
        "                    func()\n",
        "                pbar.update(1)\n",
        "                time.sleep(0.2)\n",
        "\n",
        "        return self.inference_result\n",
        "\n",
        "    def _align_and_predict(self):\n",
        "        if not self.selected_features:\n",
        "            raise ValueError(\"Model not trained. No selected features found.\")\n",
        "        if not self.training_feature_order:\n",
        "            raise ValueError(\"Training feature order missing.\")\n",
        "\n",
        "        current_features = set(self.processed_df.columns)\n",
        "        required_features = set(self.selected_features)\n",
        "\n",
        "        missing_features = required_features - current_features\n",
        "        extra_features = current_features - required_features\n",
        "\n",
        "        print(\"\\nFeature Alignment Analysis:\")\n",
        "        print(f\"  • Model features: {len(self.selected_features)}\")\n",
        "        print(f\"  • Available features: {len(self.processed_df.columns)}\")\n",
        "        if missing_features:\n",
        "            print(f\"  • Missing features (filled with 0): {len(missing_features)}\")\n",
        "        if extra_features:\n",
        "            print(f\"  • Extra features (ignored): {len(extra_features)}\")\n",
        "\n",
        "        print(\"\\nAligning features with training schema...\")\n",
        "        aligned_df = pd.DataFrame(index=self.processed_df.index)\n",
        "\n",
        "        with tqdm(total=len(self.training_feature_order), desc=\"Feature Alignment\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\",\n",
        "                  colour='orange') as pbar:\n",
        "            for feat in self.training_feature_order:\n",
        "                if feat in self.processed_df.columns:\n",
        "                    aligned_df[feat] = self.processed_df[feat]\n",
        "                else:\n",
        "                    aligned_df[feat] = 0\n",
        "                pbar.update(1)\n",
        "\n",
        "        prediction_steps = [\"Scaling features\", \"Selecting model features\", \"Generating predictions\"]\n",
        "\n",
        "        with tqdm(total=len(prediction_steps), desc=\"Prediction\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\",\n",
        "                  colour='purple') as pred_pbar:\n",
        "\n",
        "            pred_pbar.set_description(\"Scaling features\")\n",
        "            X_scaled = pd.DataFrame(\n",
        "                self.scaler.transform(aligned_df),\n",
        "                columns=self.training_feature_order,\n",
        "                index=aligned_df.index\n",
        "            )\n",
        "            pred_pbar.update(1)\n",
        "\n",
        "            pred_pbar.set_description(\"Selecting features\")\n",
        "            X_model = X_scaled[self.selected_features]\n",
        "            pred_pbar.update(1)\n",
        "\n",
        "            pred_pbar.set_description(\"Making predictions\")\n",
        "            probs = self.model.predict_proba(X_model)[:, 1]\n",
        "\n",
        "            # Set a custom threshold to control sensitivity\n",
        "            custom_threshold = 0.80\n",
        "            preds = (probs >= custom_threshold).astype(int)\n",
        "            pred_pbar.update(1)\n",
        "\n",
        "        self.inference_result = pd.DataFrame({\n",
        "            'fromaddress': self.processed_df.index,\n",
        "            'predicted_is_sybil': preds,\n",
        "            'sybil_probability': probs\n",
        "        })\n",
        "\n",
        "        sybil_count = self.inference_result['predicted_is_sybil'].sum()\n",
        "        total_count = len(self.inference_result)\n",
        "        sybil_pct = (sybil_count / total_count) * 100\n",
        "\n",
        "        print(f\"\\nPrediction Results:\")\n",
        "        print(f\"  • Total addresses: {total_count:,}\")\n",
        "        print(f\"  • Predicted Sybil: {sybil_count:,} ({sybil_pct:.1f}%)\")\n",
        "        print(f\"  • Predicted Legitimate: {total_count - sybil_count:,} ({100 - sybil_pct:.1f}%)\")\n",
        "\n",
        "    def save_model_artifacts(self, directory=\"model_artifacts\"):\n",
        "        print(f\"\\nSaving model artifacts to '{directory}'...\")\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "        artifacts = [\n",
        "            (\"Model\", self.model, \"sybil_model.pkl\"),\n",
        "            (\"Selected Features\", self.selected_features, \"selected_features.pkl\"),\n",
        "            (\"Scaler\", self.scaler, \"scaler.pkl\"),\n",
        "            (\"Encoders\", self.encoders, \"encoders.pkl\"),\n",
        "            (\"Feature Order\", self.training_feature_order, \"training_feature_order.pkl\")\n",
        "        ]\n",
        "\n",
        "        with tqdm(total=len(artifacts), desc=\"Saving Artifacts\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\",\n",
        "                  colour='green') as pbar:\n",
        "            for name, obj, filename in artifacts:\n",
        "                pbar.set_description(f\"Saving: {name}\")\n",
        "                joblib.dump(obj, f\"{directory}/{filename}\")\n",
        "                pbar.update(1)\n",
        "\n",
        "        print(\"Model artifacts saved successfully.\")\n",
        "\n",
        "    def load_model_artifacts(self, directory=\"model_artifacts\"):\n",
        "        print(f\"\\nLoading model artifacts from '{directory}'...\")\n",
        "\n",
        "        artifacts = [\n",
        "            (\"Model\", \"sybil_model.pkl\"),\n",
        "            (\"Selected Features\", \"selected_features.pkl\"),\n",
        "            (\"Scaler\", \"scaler.pkl\"),\n",
        "            (\"Encoders\", \"encoders.pkl\"),\n",
        "            (\"Feature Order\", \"training_feature_order.pkl\")\n",
        "        ]\n",
        "\n",
        "        with tqdm(total=len(artifacts), desc=\"Loading Artifacts\",\n",
        "                  bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\",\n",
        "                  colour='blue') as pbar:\n",
        "            for name, filename in artifacts:\n",
        "                pbar.set_description(f\"Loading: {name}\")\n",
        "                if name == \"Model\":\n",
        "                    self.model = joblib.load(f\"{directory}/{filename}\")\n",
        "                elif name == \"Selected Features\":\n",
        "                    self.selected_features = joblib.load(f\"{directory}/{filename}\")\n",
        "                elif name == \"Scaler\":\n",
        "                    self.scaler = joblib.load(f\"{directory}/{filename}\")\n",
        "                elif name == \"Encoders\":\n",
        "                    self.encoders = joblib.load(f\"{directory}/{filename}\")\n",
        "                elif name == \"Feature Order\":\n",
        "                    self.training_feature_order = joblib.load(f\"{directory}/{filename}\")\n",
        "                pbar.update(1)\n",
        "\n",
        "        print(\"Model artifacts loaded successfully.\")\n",
        "\n",
        "    def run_full_pipeline(self):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"EXECUTING FULL SYBIL DETECTION PIPELINE\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        pipeline_start = time.time()\n",
        "\n",
        "        self.aggregate_features()\n",
        "        self.handle_missing_values()\n",
        "        self.encode_categorical_features()\n",
        "        self.remove_low_variance_features()\n",
        "        X_train, X_test, y_train, y_test = self.prepare_for_modeling()\n",
        "        self.run_model_with_top_17_features(X_train, X_test, y_train, y_test)\n",
        "\n",
        "        pipeline_duration = time.time() - pipeline_start\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"PIPELINE EXECUTION COMPLETED\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Total execution time: {pipeline_duration:.2f} seconds\")\n",
        "        print(\"Pipeline ready for inference or model saving.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5763edef-2862-493e-ba58-394d2eea5275",
      "metadata": {
        "scrolled": true,
        "id": "5763edef-2862-493e-ba58-394d2eea5275"
      },
      "outputs": [],
      "source": [
        "cleaned_df=pd.read_csv('cleaned_df.csv', sep=',', low_memory=False)\n",
        "unlabeled_merged = cleaned_df.drop(columns='is_sybil')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d6c7ca-f9db-4761-a8d7-a6062f23e7b1",
      "metadata": {
        "scrolled": true,
        "collapsed": true,
        "id": "86d6c7ca-f9db-4761-a8d7-a6062f23e7b1",
        "outputId": "55019983-9ba4-4498-ac77-946cbe27741d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2266619 entries, 0 to 2266618\n",
            "Data columns (total 28 columns):\n",
            " #   Column                       Dtype  \n",
            "---  ------                       -----  \n",
            " 0   Unnamed: 0                   int64  \n",
            " 1   detecttime                   object \n",
            " 2   hash                         object \n",
            " 3   status                       object \n",
            " 4   region                       object \n",
            " 5   curblocknumber               float64\n",
            " 6   failurereason                object \n",
            " 7   blockspending                float64\n",
            " 8   time_pending_by_blocknative  float64\n",
            " 9   nonce                        float64\n",
            " 10  gas                          float64\n",
            " 11  gasprice                     float64\n",
            " 12  value                        object \n",
            " 13  toaddress                    object \n",
            " 14  fromaddress                  object \n",
            " 15  type                         float64\n",
            " 16  maxpriorityfeepergas         float64\n",
            " 17  maxfeepergas                 float64\n",
            " 18  basefeepergas                float64\n",
            " 19  stuck                        bool   \n",
            " 20  gasused                      float64\n",
            " 21  detect_date                  object \n",
            " 22  was_evicted                  float64\n",
            " 23  drop_reason                  object \n",
            " 24  was_rejected                 float64\n",
            " 25  rejection_reason             object \n",
            " 26  time_pending                 float64\n",
            " 27  is_sybil                     bool   \n",
            "dtypes: bool(2), float64(14), int64(1), object(11)\n",
            "memory usage: 453.9+ MB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>detecttime</th>\n",
              "      <th>hash</th>\n",
              "      <th>status</th>\n",
              "      <th>region</th>\n",
              "      <th>curblocknumber</th>\n",
              "      <th>failurereason</th>\n",
              "      <th>blockspending</th>\n",
              "      <th>time_pending_by_blocknative</th>\n",
              "      <th>nonce</th>\n",
              "      <th>gas</th>\n",
              "      <th>gasprice</th>\n",
              "      <th>value</th>\n",
              "      <th>toaddress</th>\n",
              "      <th>fromaddress</th>\n",
              "      <th>type</th>\n",
              "      <th>maxpriorityfeepergas</th>\n",
              "      <th>maxfeepergas</th>\n",
              "      <th>basefeepergas</th>\n",
              "      <th>stuck</th>\n",
              "      <th>gasused</th>\n",
              "      <th>detect_date</th>\n",
              "      <th>was_evicted</th>\n",
              "      <th>drop_reason</th>\n",
              "      <th>was_rejected</th>\n",
              "      <th>rejection_reason</th>\n",
              "      <th>time_pending</th>\n",
              "      <th>is_sybil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2024-01-15 00:00:25.570000+00:00</td>\n",
              "      <td>0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...</td>\n",
              "      <td>failed</td>\n",
              "      <td>us-east-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11248.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>215884.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>163000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.624710e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>177381.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2024-01-15 00:00:25.570000+00:00</td>\n",
              "      <td>0xf52d98d43063a4a11205ee4d3d033da746806322478d...</td>\n",
              "      <td>failed</td>\n",
              "      <td>us-east-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4895.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>242490.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0x2a40d415f217a5ff50bb92885aa55c8898b6981f</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.482984e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>199552.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2024-01-15 00:00:25.955000+00:00</td>\n",
              "      <td>0xf52d98d43063a4a11205ee4d3d033da746806322478d...</td>\n",
              "      <td>failed</td>\n",
              "      <td>eu-central-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>242490.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0x2a40d415f217a5ff50bb92885aa55c8898b6981f</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.482984e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>199552.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2024-01-15 00:00:25.955000+00:00</td>\n",
              "      <td>0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...</td>\n",
              "      <td>failed</td>\n",
              "      <td>eu-central-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>890.0</td>\n",
              "      <td>215884.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>163000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.624710e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>177381.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2024-01-15 00:00:26.081000+00:00</td>\n",
              "      <td>0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...</td>\n",
              "      <td>failed</td>\n",
              "      <td>ap-southeast-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>890.0</td>\n",
              "      <td>215884.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>163000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.624710e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>177381.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                        detecttime  \\\n",
              "0           0  2024-01-15 00:00:25.570000+00:00   \n",
              "1           1  2024-01-15 00:00:25.570000+00:00   \n",
              "2           2  2024-01-15 00:00:25.955000+00:00   \n",
              "3           3  2024-01-15 00:00:25.955000+00:00   \n",
              "4           4  2024-01-15 00:00:26.081000+00:00   \n",
              "\n",
              "                                                hash  status          region  \\\n",
              "0  0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...  failed       us-east-1   \n",
              "1  0xf52d98d43063a4a11205ee4d3d033da746806322478d...  failed       us-east-1   \n",
              "2  0xf52d98d43063a4a11205ee4d3d033da746806322478d...  failed    eu-central-1   \n",
              "3  0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...  failed    eu-central-1   \n",
              "4  0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...  failed  ap-southeast-1   \n",
              "\n",
              "   curblocknumber             failurereason  blockspending  \\\n",
              "0      19008566.0  Reverted: \\0x849eaf98\\\"\"            2.0   \n",
              "1      19008566.0  Reverted: \\0x849eaf98\\\"\"            1.0   \n",
              "2      19008566.0  Reverted: \\0x849eaf98\\\"\"            NaN   \n",
              "3      19008566.0  Reverted: \\0x849eaf98\\\"\"            NaN   \n",
              "4      19008566.0  Reverted: \\0x849eaf98\\\"\"            NaN   \n",
              "\n",
              "   time_pending_by_blocknative  nonce       gas  gasprice               value  \\\n",
              "0                      11248.0  890.0  215884.0       NaN  163000000000000000   \n",
              "1                       4895.0   21.0  242490.0       NaN  380000000000000000   \n",
              "2                          NaN   21.0  242490.0       NaN  380000000000000000   \n",
              "3                          NaN  890.0  215884.0       NaN  163000000000000000   \n",
              "4                          NaN  890.0  215884.0       NaN  163000000000000000   \n",
              "\n",
              "                                    toaddress  \\\n",
              "0  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "1  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "2  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "3  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "4  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "\n",
              "                                  fromaddress  type  maxpriorityfeepergas  \\\n",
              "0  0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba   2.0           100000000.0   \n",
              "1  0x2a40d415f217a5ff50bb92885aa55c8898b6981f   2.0           100000000.0   \n",
              "2  0x2a40d415f217a5ff50bb92885aa55c8898b6981f   2.0           100000000.0   \n",
              "3  0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba   2.0           100000000.0   \n",
              "4  0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba   2.0           100000000.0   \n",
              "\n",
              "   maxfeepergas  basefeepergas  stuck   gasused detect_date  was_evicted  \\\n",
              "0  2.624710e+10   2.131496e+10  False  177381.0  2024-01-15          NaN   \n",
              "1  2.482984e+10   2.131496e+10  False  199552.0  2024-01-15          NaN   \n",
              "2  2.482984e+10   2.131496e+10  False  199552.0  2024-01-15          NaN   \n",
              "3  2.624710e+10   2.131496e+10  False  177381.0  2024-01-15          NaN   \n",
              "4  2.624710e+10   2.131496e+10  False  177381.0  2024-01-15          NaN   \n",
              "\n",
              "  drop_reason  was_rejected rejection_reason  time_pending  is_sybil  \n",
              "0         NaN           NaN              NaN           NaN     False  \n",
              "1         NaN           NaN              NaN           NaN     False  \n",
              "2         NaN           NaN              NaN           NaN     False  \n",
              "3         NaN           NaN              NaN           NaN     False  \n",
              "4         NaN           NaN              NaN           NaN     False  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_df.info()\n",
        "cleaned_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f542bd-1d29-4ba7-8d06-dda48637fef3",
      "metadata": {
        "scrolled": true,
        "id": "22f542bd-1d29-4ba7-8d06-dda48637fef3",
        "outputId": "472825a5-c59f-4ef2-e1dc-9839da0fd17a",
        "colab": {
          "referenced_widgets": [
            "dccc01265af34571b543c30565af6403",
            "e91511cbc68e4f45b1cab5bf8d1ec87e",
            "4abaa5dfc6c0413ea1808373d622c774",
            "7f9b8ba73a094064b009fb6bfc29457c",
            "91d9a54f92b04fbdbacd8fa84fc5d9ec"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SYBIL DETECTION PIPELINE INITIALIZED\n",
            "============================================================\n",
            "\n",
            "ORIGINAL DATASET:\n",
            "----------------------------------------\n",
            "Shape: 2,266,620 rows × 27 columns\n",
            "Target Distribution:\n",
            "  • Non-Sybil: 2,241,012 (98.9%)\n",
            "  • Sybil:     25,608 (1.1%)\n",
            "Missing Values: 5,560,202\n",
            "\n",
            "============================================================\n",
            "EXECUTING FULL SYBIL DETECTION PIPELINE\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PHASE 1: FEATURE AGGREGATION\n",
            "============================================================\n",
            "\n",
            "Preprocessing Data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dccc01265af34571b543c30565af6403",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Preprocessing:   0%|          | 0/3 [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aggregating 13 numeric features...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e91511cbc68e4f45b1cab5bf8d1ec87e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Numeric Aggregation:   0%|          | 0/13 [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aggregating transaction statistics...\n",
            "Creating derived ratio features...\n",
            "\n",
            "Feature aggregation completed successfully.\n",
            "Result: 126,718 addresses with 93 features\n",
            "\n",
            "============================================================\n",
            "PHASE 2: MISSING VALUE HANDLING\n",
            "============================================================\n",
            "No missing values found - skipping this phase.\n",
            "\n",
            "============================================================\n",
            "PHASE 3: CATEGORICAL ENCODING\n",
            "============================================================\n",
            "Encoding 1 categorical features...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4abaa5dfc6c0413ea1808373d622c774",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Encoding Categories:   0%|          | 0/1 [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorical encoding completed for 1 features.\n",
            "\n",
            "============================================================\n",
            "PHASE 4: LOW VARIANCE FEATURE REMOVAL\n",
            "============================================================\n",
            "Analyzing feature variance...\n",
            "Removed 2 low variance features:\n",
            "  • success_rate\n",
            "  • failure_rate\n",
            "\n",
            "============================================================\n",
            "PHASE 5: DATA PREPARATION FOR MODELING\n",
            "============================================================\n",
            "Scaling features...\n",
            "Splitting dataset...\n",
            "Dataset prepared successfully:\n",
            "  • Training set: 101,374 samples\n",
            "  • Test set: 25,344 samples\n",
            "  • Features: 90\n",
            "\n",
            "============================================================\n",
            "PHASE 6: MODEL TRAINING & EVALUATION\n",
            "============================================================\n",
            "Selecting top 17 features using mutual information...\n",
            "\n",
            "Selected Features:\n",
            "   1. nonce_mean\n",
            "   2. gas_mean\n",
            "   3. gas_min\n",
            "   4. gas_max\n",
            "   5. gas_median\n",
            "   6. value_mean\n",
            "   7. value_min\n",
            "   8. value_max\n",
            "   9. value_median\n",
            "  10. gasused_mean\n",
            "  11. gasused_min\n",
            "  12. gasused_max\n",
            "  13. gasused_median\n",
            "  14. maxfeepergas_count\n",
            "  15. maxfeepergas_mean\n",
            "  16. maxfeepergas_max\n",
            "  17. basefeepergas_max\n",
            "\n",
            "Applying SMOTE for class balancing...\n",
            "Training set after SMOTE: 193,482 samples\n",
            "\n",
            "Training XGBoost classifier...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f9b8ba73a094064b009fb6bfc29457c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Model:   0%|          | 00:00"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating predictions...\n",
            "\n",
            "============================================================\n",
            "MODEL EVALUATION RESULTS (Threshold = 0.7)\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      0.95      0.97     24186\n",
            "        True       0.44      0.76      0.56      1158\n",
            "\n",
            "    accuracy                           0.94     25344\n",
            "   macro avg       0.71      0.86      0.76     25344\n",
            "weighted avg       0.96      0.94      0.95     25344\n",
            "\n",
            "ROC AUC Score: 0.9565\n",
            "\n",
            "============================================================\n",
            "PIPELINE EXECUTION COMPLETED\n",
            "============================================================\n",
            "Total execution time: 122.44 seconds\n",
            "Pipeline ready for inference or model saving.\n",
            "\n",
            "Saving model artifacts to 'model_artifacts'...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91d9a54f92b04fbdbacd8fa84fc5d9ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving Artifacts:   0%|          | 0/5"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model artifacts saved successfully.\n"
          ]
        }
      ],
      "source": [
        "pipeline = InteractiveSybilDetectionPipeline(cleaned_df)\n",
        "pipeline.run_full_pipeline()\n",
        "pipeline.save_model_artifacts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e19a59ad-8c03-4e97-8bc5-00225a57749f",
      "metadata": {
        "scrolled": true,
        "id": "e19a59ad-8c03-4e97-8bc5-00225a57749f",
        "outputId": "b9e17c52-eece-45b4-9e12-3c42ccf32130"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>detecttime</th>\n",
              "      <th>hash</th>\n",
              "      <th>status</th>\n",
              "      <th>region</th>\n",
              "      <th>curblocknumber</th>\n",
              "      <th>failurereason</th>\n",
              "      <th>blockspending</th>\n",
              "      <th>time_pending_by_blocknative</th>\n",
              "      <th>nonce</th>\n",
              "      <th>gas</th>\n",
              "      <th>gasprice</th>\n",
              "      <th>value</th>\n",
              "      <th>toaddress</th>\n",
              "      <th>fromaddress</th>\n",
              "      <th>type</th>\n",
              "      <th>maxpriorityfeepergas</th>\n",
              "      <th>maxfeepergas</th>\n",
              "      <th>basefeepergas</th>\n",
              "      <th>stuck</th>\n",
              "      <th>gasused</th>\n",
              "      <th>detect_date</th>\n",
              "      <th>was_evicted</th>\n",
              "      <th>drop_reason</th>\n",
              "      <th>was_rejected</th>\n",
              "      <th>rejection_reason</th>\n",
              "      <th>time_pending</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-01-15 00:00:25.570000+00:00</td>\n",
              "      <td>0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...</td>\n",
              "      <td>failed</td>\n",
              "      <td>us-east-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11248.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>215884.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>163000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.624710e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>177381.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-01-15 00:00:25.570000+00:00</td>\n",
              "      <td>0xf52d98d43063a4a11205ee4d3d033da746806322478d...</td>\n",
              "      <td>failed</td>\n",
              "      <td>us-east-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4895.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>242490.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0x2a40d415f217a5ff50bb92885aa55c8898b6981f</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.482984e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>199552.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-01-15 00:00:25.955000+00:00</td>\n",
              "      <td>0xf52d98d43063a4a11205ee4d3d033da746806322478d...</td>\n",
              "      <td>failed</td>\n",
              "      <td>eu-central-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>242490.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0x2a40d415f217a5ff50bb92885aa55c8898b6981f</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.482984e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>199552.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-01-15 00:00:25.955000+00:00</td>\n",
              "      <td>0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...</td>\n",
              "      <td>failed</td>\n",
              "      <td>eu-central-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>890.0</td>\n",
              "      <td>215884.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>163000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.624710e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>177381.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-01-15 00:00:26.081000+00:00</td>\n",
              "      <td>0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...</td>\n",
              "      <td>failed</td>\n",
              "      <td>ap-southeast-1</td>\n",
              "      <td>19008566.0</td>\n",
              "      <td>Reverted: \\0x849eaf98\\\"\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>890.0</td>\n",
              "      <td>215884.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>163000000000000000</td>\n",
              "      <td>0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad</td>\n",
              "      <td>0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100000000.0</td>\n",
              "      <td>2.624710e+10</td>\n",
              "      <td>2.131496e+10</td>\n",
              "      <td>False</td>\n",
              "      <td>177381.0</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         detecttime  \\\n",
              "0  2024-01-15 00:00:25.570000+00:00   \n",
              "1  2024-01-15 00:00:25.570000+00:00   \n",
              "2  2024-01-15 00:00:25.955000+00:00   \n",
              "3  2024-01-15 00:00:25.955000+00:00   \n",
              "4  2024-01-15 00:00:26.081000+00:00   \n",
              "\n",
              "                                                hash  status          region  \\\n",
              "0  0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...  failed       us-east-1   \n",
              "1  0xf52d98d43063a4a11205ee4d3d033da746806322478d...  failed       us-east-1   \n",
              "2  0xf52d98d43063a4a11205ee4d3d033da746806322478d...  failed    eu-central-1   \n",
              "3  0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...  failed    eu-central-1   \n",
              "4  0x0faeff4cb2ed1d589cd3c45cfdf64a9e0f037834b738...  failed  ap-southeast-1   \n",
              "\n",
              "   curblocknumber             failurereason  blockspending  \\\n",
              "0      19008566.0  Reverted: \\0x849eaf98\\\"\"            2.0   \n",
              "1      19008566.0  Reverted: \\0x849eaf98\\\"\"            1.0   \n",
              "2      19008566.0  Reverted: \\0x849eaf98\\\"\"            NaN   \n",
              "3      19008566.0  Reverted: \\0x849eaf98\\\"\"            NaN   \n",
              "4      19008566.0  Reverted: \\0x849eaf98\\\"\"            NaN   \n",
              "\n",
              "   time_pending_by_blocknative  nonce       gas  gasprice               value  \\\n",
              "0                      11248.0  890.0  215884.0       NaN  163000000000000000   \n",
              "1                       4895.0   21.0  242490.0       NaN  380000000000000000   \n",
              "2                          NaN   21.0  242490.0       NaN  380000000000000000   \n",
              "3                          NaN  890.0  215884.0       NaN  163000000000000000   \n",
              "4                          NaN  890.0  215884.0       NaN  163000000000000000   \n",
              "\n",
              "                                    toaddress  \\\n",
              "0  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "1  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "2  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "3  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "4  0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad   \n",
              "\n",
              "                                  fromaddress  type  maxpriorityfeepergas  \\\n",
              "0  0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba   2.0           100000000.0   \n",
              "1  0x2a40d415f217a5ff50bb92885aa55c8898b6981f   2.0           100000000.0   \n",
              "2  0x2a40d415f217a5ff50bb92885aa55c8898b6981f   2.0           100000000.0   \n",
              "3  0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba   2.0           100000000.0   \n",
              "4  0xe5b427d12ce20ddb478f5c15bde4ed74414ed0ba   2.0           100000000.0   \n",
              "\n",
              "   maxfeepergas  basefeepergas  stuck   gasused detect_date  was_evicted  \\\n",
              "0  2.624710e+10   2.131496e+10  False  177381.0  2024-01-15          NaN   \n",
              "1  2.482984e+10   2.131496e+10  False  199552.0  2024-01-15          NaN   \n",
              "2  2.482984e+10   2.131496e+10  False  199552.0  2024-01-15          NaN   \n",
              "3  2.624710e+10   2.131496e+10  False  177381.0  2024-01-15          NaN   \n",
              "4  2.624710e+10   2.131496e+10  False  177381.0  2024-01-15          NaN   \n",
              "\n",
              "  drop_reason  was_rejected rejection_reason  time_pending  \n",
              "0         NaN           NaN              NaN           NaN  \n",
              "1         NaN           NaN              NaN           NaN  \n",
              "2         NaN           NaN              NaN           NaN  \n",
              "3         NaN           NaN              NaN           NaN  \n",
              "4         NaN           NaN              NaN           NaN  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unlabeled_merged.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96d15c9-ab92-4405-b25d-fd7223fe9f79",
      "metadata": {
        "scrolled": true,
        "id": "f96d15c9-ab92-4405-b25d-fd7223fe9f79",
        "outputId": "59888302-de73-4392-f0b0-b72eb2ecd0f8",
        "colab": {
          "referenced_widgets": [
            "6e39292fc8074dacaf02c58a22656e6c",
            "4a738c7592394768a8f504476fecc7a6",
            "fb8a62568e914045b95888e93e758544",
            "78b4773c932744098e9e84fe87ff1c21",
            "687658e1ce9d4881a5d84f73643b8a5e",
            "e9536f5a4e3d4756856d071f26082d53",
            "3e83dc7d6ced488daafd8dc7646c8d9e"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SYBIL DETECTION PIPELINE INITIALIZED\n",
            "============================================================\n",
            "\n",
            "ORIGINAL DATASET:\n",
            "----------------------------------------\n",
            "Shape: 2,266,620 rows × 26 columns\n",
            "Target Distribution: 'is_sybil' column not found.\n",
            "Missing Values: 5,560,202\n",
            "\n",
            "Loading model artifacts from 'model_artifacts'...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e39292fc8074dacaf02c58a22656e6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading Artifacts:   0%|          | 0/5"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model artifacts loaded successfully.\n",
            "\n",
            "============================================================\n",
            "INFERENCE PIPELINE\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a738c7592394768a8f504476fecc7a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Inference Progress:   0%|          | 0/5 [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "PHASE 1: FEATURE AGGREGATION\n",
            "============================================================\n",
            "\n",
            "Preprocessing Data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb8a62568e914045b95888e93e758544",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Preprocessing:   0%|          | 0/3 [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aggregating 13 numeric features...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78b4773c932744098e9e84fe87ff1c21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Numeric Aggregation:   0%|          | 0/13 [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aggregating transaction statistics...\n",
            "Creating derived ratio features...\n",
            "\n",
            "Feature aggregation completed successfully.\n",
            "Result: 126,718 addresses with 92 features\n",
            "\n",
            "============================================================\n",
            "PHASE 2: MISSING VALUE HANDLING\n",
            "============================================================\n",
            "No missing values found - skipping this phase.\n",
            "\n",
            "============================================================\n",
            "PHASE 3: CATEGORICAL ENCODING\n",
            "============================================================\n",
            "Encoding 1 categorical features...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "687658e1ce9d4881a5d84f73643b8a5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Encoding Categories:   0%|          | 0/1 [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorical encoding completed for 1 features.\n",
            "\n",
            "============================================================\n",
            "PHASE 4: LOW VARIANCE FEATURE REMOVAL\n",
            "============================================================\n",
            "Analyzing feature variance...\n",
            "Removed 16 low variance features:\n",
            "  • was_evicted_mean\n",
            "  • was_evicted_std\n",
            "  • was_evicted_max\n",
            "  • was_evicted_median\n",
            "  • was_rejected_mean\n",
            "  • ... and 11 more\n",
            "\n",
            "Feature Alignment Analysis:\n",
            "  • Model features: 17\n",
            "  • Available features: 76\n",
            "  • Extra features (ignored): 59\n",
            "\n",
            "Aligning features with training schema...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9536f5a4e3d4756856d071f26082d53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Feature Alignment:   0%|          | 0/90"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e83dc7d6ced488daafd8dc7646c8d9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Prediction:   0%|          | 0/3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction Results:\n",
            "  • Total addresses: 126,718\n",
            "  • Predicted Sybil: 4,351 (3.4%)\n",
            "  • Predicted Legitimate: 122,367 (96.6%)\n"
          ]
        }
      ],
      "source": [
        "pipeline = InteractiveSybilDetectionPipeline(unlabeled_merged)\n",
        "\n",
        "pipeline.load_model_artifacts()\n",
        "predictions = pipeline.predict_sybil_addresses(unlabeled_merged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b19f28-caba-49ec-a1a7-6e6e35e4fd0c",
      "metadata": {
        "scrolled": true,
        "id": "63b19f28-caba-49ec-a1a7-6e6e35e4fd0c",
        "outputId": "f5e05ac3-162a-4edd-8fed-b313d0dcf43b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fromaddress</th>\n",
              "      <th>predicted_is_sybil</th>\n",
              "      <th>sybil_probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x0000000000000f25a072efa232d8efc0b5ce2436</td>\n",
              "      <td>0</td>\n",
              "      <td>0.045589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x000000000002e33d9a86567c6dfe6d92f6777d1e</td>\n",
              "      <td>0</td>\n",
              "      <td>0.010782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x0000000000055772357e58581a2a2c5c6d9e8f64</td>\n",
              "      <td>0</td>\n",
              "      <td>0.005391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x0000000000211b7cdd33049a9f1985013babb784</td>\n",
              "      <td>0</td>\n",
              "      <td>0.032927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x0000000000234a48603574189845c2d27028dad3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126712</th>\n",
              "      <td>0xfffe352a7d2c2a2bfde15199b9ba0a891d76dc57</td>\n",
              "      <td>0</td>\n",
              "      <td>0.194112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126713</th>\n",
              "      <td>0xfffe567b190edabd46e95db356e4e8a7331ea7d3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126714</th>\n",
              "      <td>0xffff8298631efa764238485543fcff82b878ce1e</td>\n",
              "      <td>0</td>\n",
              "      <td>0.025891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126715</th>\n",
              "      <td>0xffffab07392dbd555c8d46429fe14018ec71a5a3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.087937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126716</th>\n",
              "      <td>0xffffc18c0760319be9a54130b898c53a3c45f889</td>\n",
              "      <td>0</td>\n",
              "      <td>0.117941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>126717 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       fromaddress  predicted_is_sybil  \\\n",
              "0       0x0000000000000f25a072efa232d8efc0b5ce2436                   0   \n",
              "1       0x000000000002e33d9a86567c6dfe6d92f6777d1e                   0   \n",
              "2       0x0000000000055772357e58581a2a2c5c6d9e8f64                   0   \n",
              "3       0x0000000000211b7cdd33049a9f1985013babb784                   0   \n",
              "4       0x0000000000234a48603574189845c2d27028dad3                   0   \n",
              "...                                            ...                 ...   \n",
              "126712  0xfffe352a7d2c2a2bfde15199b9ba0a891d76dc57                   0   \n",
              "126713  0xfffe567b190edabd46e95db356e4e8a7331ea7d3                   0   \n",
              "126714  0xffff8298631efa764238485543fcff82b878ce1e                   0   \n",
              "126715  0xffffab07392dbd555c8d46429fe14018ec71a5a3                   0   \n",
              "126716  0xffffc18c0760319be9a54130b898c53a3c45f889                   0   \n",
              "\n",
              "        sybil_probability  \n",
              "0                0.045589  \n",
              "1                0.010782  \n",
              "2                0.005391  \n",
              "3                0.032927  \n",
              "4                0.046289  \n",
              "...                   ...  \n",
              "126712           0.194112  \n",
              "126713           0.006410  \n",
              "126714           0.025891  \n",
              "126715           0.087937  \n",
              "126716           0.117941  \n",
              "\n",
              "[126717 rows x 3 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions.head(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bab0c7d-ca2a-43c7-b8b0-66c78d1c97bd",
      "metadata": {
        "id": "6bab0c7d-ca2a-43c7-b8b0-66c78d1c97bd",
        "outputId": "78907b69-7677-47d6-be7d-60100e4c7959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔎 4.98% of addresses were predicted as Sybil (1).\n"
          ]
        }
      ],
      "source": [
        "percentage_non_sybil = (predictions['predicted_is_sybil'] == 1).mean() * 100\n",
        "print(f\"🔎 {percentage_non_sybil:.2f}% of addresses were predicted as Sybil (1).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d21f5c-194d-4d3b-a8d5-7d9ab8dd1c95",
      "metadata": {
        "id": "48d21f5c-194d-4d3b-a8d5-7d9ab8dd1c95"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}